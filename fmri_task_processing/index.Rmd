---
title: "Neuroconductor Example: fMRI Task Processing"
author: 'John Muschelli<br/>http://johnmuschelli.com/talks/fmri_task_processing/<br/> Johns Hopkins Bloomberg School of Public Health'
output:
  ioslides_presentation:
    css: neuroconductor.css
    self_contained: no
    widescreen: yes
    keep_md: true
  beamer_presentation: default
  slidy_presentation:
    css: neuroconductor.css
    mathjax: local
    widescreen: yes
bibliography: Oral_Proposal.bib
logo: bloomberg.logo.small.horizontal.blue.png
---
<style type="text/css">
article {
  font-size: 30pt;
}
</style>


```{r setup, include=FALSE, message = FALSE}
knitr::opts_chunk$set(echo = FALSE, prompt = FALSE, message = FALSE, warning = FALSE, comment = "", results = 'hide')
library(pander)
library(rvest)
library(httr)
library(neurobase)
library(matlabr)
library(spm12r)
library(tidyr)
library(ggplot2)
t1_fname = "anat.nii.gz"
```


# Worked Example<br>Disclaimer: there is no universal fMRI pipeline

# `spm12r` Worked Example<br>Disclaimer: there is no universal fMRI pipeline

## Data required for analysis

- One anatomical T1-weighted scan: `anat.nii.gz`
- One 4D fMRI task-related scan: `fmri.nii.gz`.  
- Information on design:
    - onsets/duration of stimuli
- Order of slices (which was first slice) 
    - or time slice measured (in ms).
- Repetition time (TR) from DICOM header/scanner/tech.

## Worked example: DICOM conversion

- DICOM to NIfTI: Convert the data using `dcm2niix` (https://github.com/rordenlab/dcm2niix).
- `dcm2niir`: https://github.com/muschellij2/dcm2niir
- `divest`: https://github.com/jonclayden/divest

```{r, eval = FALSE}
divest_result = divest::readDicom(path = "/path/to/DICOMs")
dcm2niir_result = dcm2niir::dcm2nii(basedir = "/path/to/DICOMs")
```

# Explore the Raw Data: <br><br>http://bit.ly/neuroshiny

## Download the data 

https://figshare.com/articles/SFO-example/5442298

```{r makefiles, echo = TRUE, eval = FALSE}
url = paste0("https://ndownloader.figshare.com/articles/",
             "5442298/versions/1")
# download a temporary zip file
zipfile = tempfile(fileext = ".zip")
res = httr::GET(url, write_disk(path = zipfile))

####### unzip file code (not shown) ###########

out_files = c("anat.nii.gz", "fmri.nii.gz")
```


```{r makefiles_run, echo = FALSE, cache = TRUE, eval = TRUE}
library(httr)
out_files = c("anat.nii.gz", "fmri.nii.gz")
if (!all(file.exists(out_files))) {
  url = paste0(
    "https://ndownloader.figshare.com/articles/",
    "5442298/versions/1")
  zipfile = tempfile(fileext = ".zip")
  res = GET(url, 
            write_disk(path = zipfile),
            if (interactive()) progress())
  run_dir = "."
  if (!dir.exists(run_dir)) {
    dir.create(run_dir)
  }
  out_files = utils::unzip(zipfile, exdir = run_dir)
  names(out_files) = neurobase::nii.stub(out_files, bn = TRUE)
  file.remove(zipfile)
}
```

## fMRI information

```{r, eval = TRUE, echo = TRUE, results='markup'}
fmri_filename = "fmri.nii.gz"
tr = 1.8 # seconds
# getting nifti header
hdr = neurobase::check_nifti_header(fmri_filename)

(nslices = oro.nifti::nsli(hdr))
(n_time_points = oro.nifti::ntim(hdr))
time_points = seq(n_time_points)
hdr
```

## Types of Registration
<div style="font-size: 20pt;">

- Rigid-body registration (linear) - 6 degrees of freedom (dof)

<img src="rollpitchyaw.png" style="width: 50%; display: block; margin: auto;">
<div style="font-size: 8pt">
Image taken from [http://cnl.web.arizona.edu/imageprops.htm](http://cnl.web.arizona.edu/imageprops.htm)
</div>

- Pitch - Think of nodding ("yes")
- Yaw - Think of shaking head ("no") 
- Roll - Think of shoulder shrugging ("I don't know")
- x – left/right, y – forward/backward, z – jump up/down 

</div>

## Rigid Registration: The Math

<div style="font-size: 20pt;">

For a voxel $v$, the rigid transformation can be written as:

$$T_{\rm rigid}(v) = Rv + t$$
where $R =$
\small
$$\left[\begin{array}{ccc} \cos\beta\cos\gamma& \cos\alpha\sin\gamma + \sin\alpha\sin\beta\cos\gamma & \sin\alpha\sin\gamma - \cos\alpha\sin\beta\cos\gamma \\
-\cos\beta\sin\gamma & \cos\alpha\cos\gamma - \sin\alpha\sin\beta\sin\gamma & \sin\alpha\cos\gamma + \cos\alpha\sin\beta\sin\gamma \\
\sin\beta & -\sin\alpha\cos\beta & \cos\alpha\cos\beta \end{array}\right]$$
\normalsize

- 6 degrees of freedom
- $3$ associated with the translation vector: $t=(t_x, t_y, t_z)$
- $3$ associated with the rotation parameters: $\theta=(\alpha, \beta,\gamma)$. 

</div>


## Image Realignment: within-fMRI registration

<center>
<img src="average.png" style="width:40%; margin: auto;" alt="flow"> 
</center>

## Image Realignment 


```{r realign, eval = FALSE, echo = TRUE}
realigned = spm12_realign(filename = fmri_filename,
  time_points = time_points,
  quality = 0.98, separation = 3,
  register_to = "mean",
  est_interp = "bspline4", reslice_interp = "bspline4")
# reading in the mean image
mean_img = realigned[["mean"]]
mean_nifti = readnii(mean_img)
rpfile = realigned[['rp']]
rp = read.table(file = rpfile, header = FALSE)
realigned$outfiles
realigned$mat
```

```{r realign_run, eval = TRUE}
# reading in the mean image
mean_img = "meanfmri.nii.gz"
mean_nifti = readnii(mean_img)
rpfile = "rp_fmri.txt"
rp = read.table(file = rpfile, header = FALSE)
print("rfmri.nii")
print("fmri.mat")
```


## Image Realignment 

<center>
<img src="realign.png" style="width:40%; margin: auto;" alt="flow"> 
</center>

### Plotting the realignment parameters

These can be used as regressors in motion correction for further analyses.

```{r rp_file, eval = FALSE, echo = TRUE}
colnames(rp) = c("x", "y", "z", "roll", "pitch", "yaw")
head(rp, 2)
```

```{r rp_plot, echo = FALSE}
transparent_legend =  theme(
  legend.background = element_rect(fill = "transparent"),
  legend.key = element_rect(fill = "transparent", 
                            color = "transparent")
)
rp = read.table(file = rpfile, header = FALSE)
ord = c("x", "y", "z", "roll", "pitch", "yaw")
colnames(rp) = ord
head(rp, 2)
# get to degrees * 180/pi
# multiply by 50 for radius of head
rp[, c("roll", "pitch", "yaw")] = rp[, c("roll", "pitch", "yaw")]  * 50
rp$t = seq(nrow(rp))
long = gather(data = rp, key = Direction, value = value, -t)
long$Direction = factor(long$Direction, levels = ord)
ggplot(aes(x = t, y = value, colour = Direction), data = long) + 
  geom_line() + ylab("Movement (mm)") + xlab("Scan Number") + 
  transparent_legend + theme(legend.position = c(0.5, 0.75)) +
  ylim(-2, 2) + theme(legend.direction = "horizontal", 
                      legend.box = "horizontal") + 
  guides(colour = guide_legend(nrow = 1))
```

## Slice timing correction - temporal alignment

<center>
<img src="slice_timing.png" style="width:60%; margin: auto;" alt="flow"> 
</center>

<div style="font-size: 20pt;">
From http://www.brainvoyager.com/bvqx/doc/UsersGuide/Preprocessing/SliceScanTimeCorrection.html
</div>

## Slice timing correction - temporal alignment


- Repetition time (from `hdr`)
- Number of time points and slices (from `hdr`)
- Need the reference slice (`ref_slice`), 
- slice order: ascending, contiguous (different for descending or interleaved)
- Time between the first and the last slice within one scan (`ta`).  `ta = 0` if you give slice order in seconds/milliseconds.

## Slice timing correction - temporal alignment

```{r, echo = TRUE}
slice_order = c(
  1740, 1680, 1620, 1560, 1500, 1440, 1380, 
  1320, 1260, 1200, 1140, 1080, 1020, 960, 
  900, 840, 780, 720, 660, 600, 540, 480, 
  420, 360, 300, 240, 180, 120, 60, 0, 
  1740, 1680, 1620, 1560, 1500, 1440, 1380, 
  1320, 1260, 1200, 1140, 1080, 1020, 960, 
  900, 840, 780, 720, 660, 600, 540, 480, 420, 
  360, 300, 240, 180, 120, 60, 0)
ref_slice = 900
ta = 0 # since slice_order in ms
```


## Slice timing correction - temporal alignment

```{r, echo = TRUE}
times = slice_order/1000
df = data.frame(time = times, slice = seq(times))
df = dplyr::arrange(df, time)
plot(x = df$time, y = df$slice, pch = 19, type = "n", xlim = c(0, 1.8))
segments(x0 = df$time, y0 = df$slice, x1 = df$time + 0.25)

x = nifti(mean_nifti)
x = cal_img(x)
x@.Data <- aperm(x, c(2, 3, 1))
col = gray(0:64/64)
zlim <- c(x@cal_min, x@cal_max)
breaks <- c(zlim[1], 
            seq(min(zlim, na.rm = TRUE), 
                max(zlim, 
                    na.rm = TRUE), 
                length = length(col) - 1), zlim[2])
dims = dim(x)
X <- nrow(x)
Y <- ncol(x)
z = 48
oldpar <- par(no.readonly = TRUE)
par(mfrow = c(1,1), mar = rep(0, 4), 
    bg = "black")
splits = split(df, df$time)
animation::saveGIF({
  for ( i in seq_along(splits)) {
    idf = splits[[idf]]
    graphics::image(1:X, 1:Y, x[, , z], col = col, 
                    breaks = breaks, bg = "black")
    abline(h = idf$slice, col = "red", lwd = 5)
  }
}, movie.name = "slice_timing.gif")
segments(0.5,0.1,0.2,0.25, col = "blue")

```


## Slice timing correction - temporal alignment

```{r slice_time, eval = FALSE, echo = TRUE}
aimg = spm12_slice_timing(filename = realigned$outfiles,
  nslices = nslices,  tr = tr, slice_order = slice_order,
  time_points = seq(n_time_points),
  ta = ta, # since slice order given in ms 
  ref_slice = ref_slice, prefix = "a")
print(aimg$outfile)
```

```{r}
aimg = "arfmri.nii"
print(aimg)
```


## Spatial Normalization: T1 Coregistration to Mean fMRI

We then perform the coregistration using `spm12_coregister_estimate`, where the fixed image is the mean image and the moving image is the anatomical.

```{r coreg, eval = FALSE, echo = TRUE}
t1_fname = "anat.nii.gz"
coreg = spm12_coregister_estimate(
  fixed = mean_img,
  moving = t1_fname, 
  cost_fun = "nmi")
coreg$outfile
```

```{r coreg_run, eval = TRUE}
print("anat.nii")
```

## Spatial Normalization: T1 Coregistration to Mean fMRI

Nothing happened!

- `spm12_coregister_estimate` - estimates coregistration (transforms the header)
- `spm12_coregister_reslice` - reslices the image to the same voxel dimensions (should probably be coregistered already using `estimate`)
- `spm12_coregister` - estimates and reslices all in one.

- Estimate the transformation, but do segmentation on native T1 space (better resolution)


## Anatomical MRI Segmentation (and Spatial Normalize Estimation)

Here we perform the segmentation of the co-registered anatomical image from above.  This will segment the image into 6 different regions, where the regions are gray matter, white matter, cerebrospinal fluid (CSF), bone, soft tissue, and the background.  

```{r seg, eval = FALSE, echo = TRUE}
seg = spm12_segment(
  filename = coreg$outfile,
  set_origin = FALSE, 
  bias_corrected = TRUE, native = TRUE,
  unmodulated = TRUE, modulated = TRUE, affine = "mni",
  sampling_distance = 1.5)
```


## Anatomical MRI Segmentation (and Spatial Normalize Estimation)

- `native` - native space segmentations
- `modulated` - adjusted segmentations to constrain tissue-class volumes
- `unmodulated` - unadjusted 
- `bias_corrected` - save bias-field corrected image
- `set_origin` - should AC/PC alignment be done (no because we just coregistered)

## Applying Spatial Normalization Transformation

Now that we have esimated the transformation from the T1 image, we can take that deformation and apply it to the fMRI data using `spm12_normalize_write`.  Again, we are registering to the MNI template and will use a standard bounding box.  We pass the anatomical, mean fMRI, and 4D fMRI data in to be transformed.  

```{r norm_write, eval = FALSE, echo = TRUE}
bounding_box = matrix(
    c(-78, -112, -70, 
      78, 76, 85), nrow = 2, 
    byrow = TRUE)
norm = spm12_normalize_write(
  deformation = seg$deformation,
  other.files = aimg$outfile,
  bounding_box = bounding_box,
  interp = "bspline5",
  retimg = FALSE)
```

## Applying Spatial Normalization Transformation


```{r anat_norm, eval = FALSE, echo = TRUE}
anat_norm = spm12_normalize_write(
  deformation = seg$deformation,
  other.files = seg$bias_corrected,
  bounding_box = bounding_box,
  interp = "bspline5",
  voxel_size = c(1, 1, 1),
  retimg = FALSE
)
```

## Applying Spatial Normalization Transformation

```{r anat_norm2x2x2, eval = FALSE, echo = TRUE}
anat_norm2x2x2 = spm12_normalize_write(
  deformation = seg$deformation,
  other.files = seg$bias_corrected,
  bounding_box = bounding_box,
  interp = "bspline5",
  voxel_size = c(2, 2, 2), # note the resolution!!!
  retimg = FALSE
)  
```



## Spatial smoothing using a Gaussian

Smoothing is specifieid using the full-width half max (FWHM) for the Gaussian smoother.  Relationship between the FWHM and the Gaussian $\sigma$:

$$
FWHM = \sigma \sqrt{8 \log(2)}
$$
where $\log$ is the natural log.  


## Spatial smoothing using a Gaussian

```{r smooth, eval = FALSE, echo = TRUE}
smooth_norm = spm12_smooth(
  norm$outfiles[[1]], 
  fwhm = 5, 
  prefix = "s5",
  retimg = FALSE)
```

In many applications, this is the data you will use for post-processing and analysis.  Motion correction has usually been applied above, but some motion correct this data as well. 

# First Level Modeling<br>Single-Subject Model

## Estimate Model 
```{r first_model, eval = FALSE}
output_directory = file.path(run_dir, "output")
if (!dir.exists(output_directory)) {
  dir.create(output_directory)
}
output_directory = normalizePath(output_directory)

################################
# Same model just using condition list
################################
condition_list = list(
  list(name = "LeftHand",
       onset = c(20, 100, 180, 260, 340, 420),
       duration = c(20, 20, 20, 20, 20, 20)
  ),
  list(name = "RightHand",
       onset = c(60, 140, 220, 300, 380, 460),
       duration = c(20, 20, 20, 20, 20, 20)
  )
)
if (have_matlab()) {
  first_model = spm12_first_level(
    scans = smooth_norm$outfiles,
    n_time_points = n_time_points,
    units = "secs",
    slice_timed = FALSE,
    tr = tr,
    condition_list = condition_list,
    regressor_mat = rpfile,
    outdir = output_directory,
    clean = FALSE
  )
  
  cons = list.files(
    pattern = "beta.*[.]nii", 
    path = output_directory,
    full.names = TRUE)
  print(cons)
}
```

## Contrast Manager - Creating Contrasts

```{r conman, eval = FALSE}
contrasts = list(
  list(
    name = "LeftHand",
    weights = c(1, rep(0, 7)),
    replicate = "none",
    type = "T" ),
  list(name = "RightHand",
       weights = c(0, 1, rep(0, 6)),
       replicate = "none",
       type = "T"), 
  list(name = "AllEffects",
       weights = rbind(
         c(1, rep(0, 7)),
         c(0, 1, rep(0, 6))
       ),
       replicate = "none",
       type = "F")   
)

  contrast_res = spm12_contrast_manager(
    spm = first_model$spmmat,
    delete_existing = TRUE,
    contrast_list = contrasts,
    clean = FALSE
  )
```

```{r gzipping, eval = FALSE}
if (have_matlab()) {
  dir(output_directory)
  
  cons = list.files(
    pattern = "con.*[.]nii", path = output_directory,
    full.names = TRUE)
  print(cons)
  stats = list.files(
    pattern = "spm(T|F).*[.]nii", 
    path = output_directory,
    full.names = TRUE)
  print(stats)
  # anat_img = readnii(anat_norm2x2x2$outfiles)
  # stat_t = readnii(stats[2])
}
```


