---
title: "Neuroconductor Example: fMRI Task Processing"
author: 'John Muschelli<br/>http://johnmuschelli.com/talks/fmri_task_processing/<br/> Johns Hopkins Bloomberg School of Public Health'
output:
  ioslides_presentation:
    css: neuroconductor.css
    self_contained: no
    widescreen: yes
    keep_md: true
  beamer_presentation: default
  slidy_presentation:
    css: neuroconductor.css
    mathjax: local
    widescreen: yes
bibliography: Oral_Proposal.bib
logo: bloomberg.logo.small.horizontal.blue.png
---
<style type="text/css">
article {
  font-size: 30pt;
}
</style>


```{r setup, include=FALSE, message = FALSE}
knitr::opts_chunk$set(echo = FALSE, prompt = FALSE, message = FALSE, warning = FALSE, comment = "", results = 'hide')
library(pander)
library(rvest)
library(httr)
library(neurobase)
library(matlabr)
library(spm12r)
library(tidyr)
library(ggplot2)
t1_fname = "anat.nii.gz"
```


## SPM

All of this is using the Statistical Parametric Mapping (SPM) [@penny2011statistical] software version 12:
- requies MATLAB (for this tutorial)
- All called through `spm12r` package: https://github.com/muschellij2/spm12r
- Many options are **specific** to this data analysis
- All code is found at https://github.com/muschellij2/talks/tree/master/fmri_task_processing


# `spm12r` Worked Example<br>Disclaimer: there is no universal fMRI pipeline

## Data required for analysis

- One anatomical T1-weighted scan: `anat.nii.gz`
- One 4D fMRI task-related scan: `fmri.nii.gz`.  
- Information on design:
    - onsets/duration of stimuli
- Order of slices (which was first slice) 
    - or time slice measured (in ms).
- Repetition time (TR) from DICOM header/scanner/tech.

## Worked example: DICOM conversion

- DICOM to NIfTI: Convert the data using `dcm2niix` (https://github.com/rordenlab/dcm2niix).
- `dcm2niir`: https://github.com/muschellij2/dcm2niir
- `divest`: https://github.com/jonclayden/divest

```{r, eval = FALSE}
divest_result = divest::readDicom(path = "/path/to/DICOMs")
dcm2niir_result = dcm2niir::dcm2nii(basedir = "/path/to/DICOMs")
```

## Download the data 

https://figshare.com/articles/SFO-example/5442298

```{r makefiles, echo = TRUE, eval = FALSE}
url = paste0("https://ndownloader.figshare.com/articles/",
             "5442298/versions/1")
# download a temporary zip file
zipfile = tempfile(fileext = ".zip")
res = httr::GET(url, write_disk(path = zipfile))

####### unzip file code (not shown) ###########

out_files = c("anat.nii.gz", "fmri.nii.gz")
```


```{r makefiles_run, echo = FALSE, cache = TRUE, eval = TRUE}
library(httr)
out_files = c("anat.nii.gz", "fmri.nii.gz")
if (!all(file.exists(out_files))) {
  url = paste0(
    "https://ndownloader.figshare.com/articles/",
    "5442298/versions/1")
  zipfile = tempfile(fileext = ".zip")
  res = GET(url, 
            write_disk(path = zipfile),
            if (interactive()) progress())
  run_dir = "."
  if (!dir.exists(run_dir)) {
    dir.create(run_dir)
  }
  out_files = utils::unzip(zipfile, exdir = run_dir)
  names(out_files) = neurobase::nii.stub(out_files, bn = TRUE)
  file.remove(zipfile)
}
```

## fMRI information

```{r, eval = TRUE, echo = TRUE, results='markup'}
fmri_filename = "fmri.nii.gz"
tr = 1.8 # seconds
# getting nifti header
hdr = neurobase::check_nifti_header(fmri_filename)

(nslices = oro.nifti::nsli(hdr))
(n_time_points = oro.nifti::ntim(hdr))
hdr
```


# Explore the Raw Data: <br><br>http://bit.ly/neuroshiny

## Explore the Data

The first part of any preprocessing pipeline should be to use exploratory techniques to investigate the raw image data and detect possible problems and artifacts.

fMRI data often contain transient spike artifacts and slow drift over time.

An exploratory technique such as principal components analysis (PCA) can be used to look for spike-related artifacts.

(courtesy of Martin Lindquist)


## Types of Registration
<div style="font-size: 20pt;">

- Rigid-body registration (linear) - 6 degrees of freedom (dof)

<img src="rollpitchyaw.png" style="width: 50%; display: block; margin: auto;">
<div style="font-size: 8pt">
Image taken from [http://cnl.web.arizona.edu/imageprops.htm](http://cnl.web.arizona.edu/imageprops.htm)
</div>

- Pitch - Think of nodding ("yes")
- Yaw - Think of shaking head ("no") 
- Roll - Think of shoulder shrugging ("I don't know")
- x – left/right, y – forward/backward, z – jump up/down 

</div>

## Rigid Registration: The Math

<div style="font-size: 20pt;">

For a voxel $v$, the rigid transformation can be written as:

$$T_{\rm rigid}(v) = Rv + t$$
where $R =$
\small
$$\left[\begin{array}{ccc} \cos\beta\cos\gamma& \cos\alpha\sin\gamma + \sin\alpha\sin\beta\cos\gamma & \sin\alpha\sin\gamma - \cos\alpha\sin\beta\cos\gamma \\
-\cos\beta\sin\gamma & \cos\alpha\cos\gamma - \sin\alpha\sin\beta\sin\gamma & \sin\alpha\cos\gamma + \cos\alpha\sin\beta\sin\gamma \\
\sin\beta & -\sin\alpha\cos\beta & \cos\alpha\cos\beta \end{array}\right]$$
\normalsize

- 6 degrees of freedom
- $3$ associated with the translation vector: $t=(t_x, t_y, t_z)$
- $3$ associated with the rotation parameters: $\theta=(\alpha, \beta,\gamma)$. 

</div>


## Image Realignment: within-fMRI registration

<center>
<img src="average.png" style="width:40%; margin: auto;" alt="flow"> 
</center>

## Image Realignment 


```{r realign, eval = FALSE, echo = TRUE}
realigned = spm12_realign(filename = fmri_filename,
  time_points = seq(n_time_points),
  quality = 0.98, separation = 3,
  register_to = "mean",
  est_interp = "bspline4", reslice_interp = "bspline4")
# reading in the mean image
mean_img = realigned[["mean"]]
mean_nifti = readnii(mean_img)
rpfile = realigned[['rp']]
rp = read.table(file = rpfile, header = FALSE)
realigned$outfiles
```
```{r, eval = TRUE, results='markup'}
print("rfmri.nii")
```
```{r, eval = FALSE, echo = TRUE}
realigned$mat
```
```{r, eval = TRUE, results='markup'}
print("fmri.mat")
```


```{r realign_run, eval = TRUE, results='markup'}
# reading in the mean image
mean_img = "meanfmri.nii.gz"
mean_nifti = readnii(mean_img)
rpfile = "rp_fmri.txt"
rp = read.table(file = rpfile, header = FALSE)

```


## Image Realignment 

<center>
<img src="realign.png" style="width:40%; margin: auto;" alt="flow"> 
</center>

### Plotting the realignment parameters

These can be used as regressors in motion correction for further analyses.

```{r rp_file, eval = FALSE, echo = TRUE}
colnames(rp) = c("x", "y", "z", "roll", "pitch", "yaw")
head(rp, 2)
```

```{r rp_plot, echo = FALSE}
transparent_legend =  theme(
  legend.background = element_rect(fill = "transparent"),
  legend.key = element_rect(fill = "transparent", 
                            color = "transparent")
)
rp = read.table(file = rpfile, header = FALSE)
ord = c("x", "y", "z", "roll", "pitch", "yaw")
colnames(rp) = ord
head(rp, 2)
# get to degrees * 180/pi
# multiply by 50 for radius of head
rp[, c("roll", "pitch", "yaw")] = rp[, c("roll", "pitch", "yaw")]  * 50
rp$t = seq(nrow(rp))
long = gather(data = rp, key = Direction, value = value, -t)
long$Direction = factor(long$Direction, levels = ord)
ggplot(aes(x = t, y = value, colour = Direction), data = long) + 
  geom_line() + ylab("Movement (mm)") + xlab("Scan Number") + 
  transparent_legend + theme(legend.position = c(0.5, 0.75)) +
  ylim(-2, 2) + theme(legend.direction = "horizontal", 
                      legend.box = "horizontal") + 
  guides(colour = guide_legend(nrow = 1))
```

## Slice timing correction - temporal alignment

<center>
<img src="slice_timing.png" style="width:60%; margin: auto;" alt="flow"> 
</center>

<div style="font-size: 20pt;">
From http://www.brainvoyager.com/bvqx/doc/UsersGuide/Preprocessing/SliceScanTimeCorrection.html
</div>



## Slice timing correction - temporal alignment

- Repetition time (from `hdr`)
- Number of time points and slices (from `hdr`)
- Need the reference slice (`ref_slice`), 
- slice order: descending, dual-coil (different for ascending or interleaved)
- Time between the first and the last slice within one scan (`ta`).  `ta = 0` if you give slice order in seconds/milliseconds.

## Slice timing correction - temporal alignment

```{r, echo = TRUE}
slice_order = c(
  1740, 1680, 1620, 1560, 1500, 1440, 1380, 
  1320, 1260, 1200, 1140, 1080, 1020, 960, 
  900, 840, 780, 720, 660, 600, 540, 480, 
  420, 360, 300, 240, 180, 120, 60, 0, 
  1740, 1680, 1620, 1560, 1500, 1440, 1380, 
  1320, 1260, 1200, 1140, 1080, 1020, 960, 
  900, 840, 780, 720, 660, 600, 540, 480, 420, 
  360, 300, 240, 180, 120, 60, 0)
ref_slice = 900
ta = 0 # since slice_order in ms
```


## <img src="slice_timing_slow.gif" style="width: 50%; display: block; margin: auto;">


## Slice timing correction - temporal alignment

```{r, echo = TRUE}
########################
# first slice is the bottom
########################
times = slice_order/1000
# need 60 - because how image works and it's ascending. 60 is bottom
df = data.frame(time = times, slice = 60 - seq(times))
df = dplyr::arrange(df, time)
plot(x = df$time, y = df$slice, pch = 19, type = "n", xlim = c(0, 1.8))
segments(x0 = df$time, y0 = df$slice, x1 = df$time + 0.25)

x = nifti(mean_nifti)
x = cal_img(x)
x@.Data <- aperm(x, c(2, 3, 1))
col = gray(0:64/64)
zlim <- c(x@cal_min, x@cal_max)
breaks <- c(zlim[1], 
            seq(min(zlim, na.rm = TRUE), 
                max(zlim, 
                    na.rm = TRUE), 
                length = length(col) - 1), zlim[2])
dims = dim(x)
X <- nrow(x)
Y <- ncol(x)
z = 48
splits = split(df, df$time)
ref_df = splits[[as.character(ref_slice/1000)]]
oldpar <- par(no.readonly = TRUE)

fname = "slice_timing.gif"
if (!file.exists(fname)) {
  animation::saveGIF({
    par(mfrow = c(1,1), mar = rep(0, 4), 
        bg = "black")  
    for (i in seq_along(splits)) {
      idf = splits[[i]]
      time_slice = unique(idf$time)
      graphics::image(1:X, 1:Y, x[, , z], col = col, 
                      breaks = breaks, bg = "black")
      abline(h = idf$slice, col = "red", lwd = 5)
      abline(h = ref_df$slice, col = "blue", lwd = 5)
      text(x = 14, y = 50, 
           labels = paste0("Time = ", time_slice, "s"), 
           cex = 1.2, col = "white")
    }
  }, movie.name = "fname", interval = 1.8/length(splits))
}

fname = "slice_timing_slow.gif"
if (!file.exists(fname)) {
  animation::saveGIF({
    par(mfrow = c(1,1), mar = rep(0, 4), 
        bg = "black")  
    for (i in seq_along(splits)) {
      idf = splits[[i]]
      time_slice = unique(idf$time)
      graphics::image(1:X, 1:Y, x[, , z], col = col, 
                      breaks = breaks, bg = "black")
      abline(h = idf$slice, col = "red", lwd = 5)
      abline(h = ref_df$slice, col = "blue", lwd = 5)
      text(x = 14, y = 50, 
           labels = paste0("Time = ", time_slice, "s"), 
           cex = 1.2, col = "white")
    }
  }, movie.name = fname, 
  interval = 1.8/length(splits) * 2)
}
par(oldpar)
```



## Slice timing correction - temporal alignment

```{r slice_time, eval = FALSE, echo = TRUE}
aimg = spm12_slice_timing(filename = realigned$outfiles,
  nslices = nslices,  tr = tr, slice_order = slice_order,
  time_points = seq(n_time_points),
  ta = ta, # since slice order given in ms 
  ref_slice = ref_slice, prefix = "a")
print(aimg$outfile)
```

```{r}
aimg = "arfmri.nii"
print(aimg)
```


## T1 Coregistration to Mean fMRI

We then perform the coregistration using `spm12_coregister_estimate`, where the fixed image is the mean image and the moving image is the anatomical.

```{r coreg, eval = FALSE, echo = TRUE}
t1_fname = "anat.nii.gz"
coreg = spm12_coregister_estimate(
  fixed = mean_img,
  moving = t1_fname, 
  cost_fun = "nmi")
coreg$outfile
```

```{r coreg_run, eval = TRUE, results='markup'}
print("anat.nii")
```

## T1 Coregistration to Mean fMRI

Nothing happened!

- `spm12_coregister_estimate` - estimates coregistration (transforms the header)
- `spm12_coregister_reslice` - reslices the image to the same voxel dimensions (should probably be coregistered already using `estimate`)
- `spm12_coregister` - estimates and reslices all in one.

- Estimate the transformation, but do segmentation on native T1 space (better resolution)


## Anatomical MRI Segmentation 

Here we segment the image into 6 different regions, where the regions are gray matter, white matter, cerebrospinal fluid (CSF), bone, soft tissue, and the background.  

```{r seg, eval = FALSE, echo = TRUE}
seg = spm12_segment(
  filename = coreg$outfile,
  set_origin = FALSE, 
  bias_corrected = TRUE, native = TRUE,
  unmodulated = TRUE, modulated = TRUE, affine = "mni",
  sampling_distance = 1.5)
```


## Anatomical MRI Segmentation 

- `native` - native space segmentations
- `modulated` - adjusted segmentations to constrain tissue-class volumes
- `unmodulated` - unadjusted 
- `bias_corrected` - save bias-field corrected image
- `set_origin` - should AC/PC alignment be done (no because we just coregistered)

## Anatomical MRI Segmentation 

```{r hard_seg, cache=TRUE, eval = TRUE, echo = FALSE, fig.align="center"}
probs = paste0("c", 1:6, "anat.nii.gz")
probs = check_nifti(probs)
hard_seg = spm_probs_to_seg(img = probs)
anat = readnii("anat.nii.gz")
double_ortho(anat, hard_seg)
rm(list = c("hard_seg", "anat"));
```

```{r hard_seg2, cache=TRUE, echo = FALSE, fig.align="center"}
probs = paste0("c", 1:6, "anat.nii.gz")
probs = check_nifti(probs)
hard_seg = spm_probs_to_seg(img = probs)
anat = readnii("anat.nii.gz")
hard_seg = mask_img(hard_seg, hard_seg >= 1 & hard_seg <= 3)
double_ortho(anat, hard_seg)
rm(list = c("hard_seg", "anat"));
```


## Spatial normalization to MNI

- My brain is not the same size/shape as your brain
- But I want to look at information across subjects spatially
- Spatial normalization allows us to transform the data, stretching and scaling the data (nonlinearly) to a standard brain.
- MNI (Montreal Neurological Institute) is the most commonly used (ICBM MNI152 of some sort, http://www.bic.mni.mcgill.ca/ServicesAtlases/ICBM152NLin2009).  

## Spatial normalization to MNI

Affine + Non-linear transform (invertible)

<center>
<img src="nonlin.png" style="width:40%; margin: auto;" alt="flow"> 
</center>

## Spatial normalization to MNI: already done

The segmentation was done by warping the T1 to the MNI template and that transform/deformation in the segmentation output:

```{r show_def, eval = FALSE, echo = TRUE}
seg$deformation
```

```{r show_def_run, eval = TRUE, echo = FALSE, results='markup'}
print("y_anat.nii")
```

## Applying spatial normalization: fMRI

We apply the deformation to the fMRI data using `spm12_normalize_write`.  

```{r norm_write, eval = FALSE, echo = TRUE}
bounding_box = matrix(
    c(-78, -112, -70, 
      78, 76, 85), nrow = 2, 
    byrow = TRUE)
norm = spm12_normalize_write(
  deformation = seg$deformation,
  other.files = aimg$outfile, #corrected fMRI
  bounding_box = bounding_box,
  interp = "bspline5")
```

## Applying spatial normalization: T1


```{r anat_norm, eval = FALSE, echo = TRUE}
anat_norm = spm12_normalize_write(
  deformation = seg$deformation,
  other.files = seg$bias_corrected,
  bounding_box = bounding_box,
  interp = "bspline5",
  voxel_size = c(1, 1, 1),
  retimg = FALSE
)
```

## Applying spatial normalization: T1, but 2x2x2

```{r anat_norm2x2x2, eval = FALSE, echo = TRUE}
anat_norm2x2x2 = spm12_normalize_write(
  deformation = seg$deformation,
  other.files = seg$bias_corrected,
  bounding_box = bounding_box,
  interp = "bspline5",
  voxel_size = c(2, 2, 2), # note the resolution!!!
  retimg = FALSE
)  
```



## Spatial smoothing using a Gaussian

- Spatial smoothing should signal to noise depending on the size of activation
- Specified using the full-width half max (FWHM) for the Gaussian smoother.  

Relationship between the FWHM and the Gaussian $\sigma$:

$$
FWHM = \sigma \sqrt{8 \log(2)}
$$
where $\log$ is the natural log.  

<div style="font-size: 20pt;">
From https://en.wikipedia.org/wiki/Gaussian_function#/media/File:Gaussian_2d.svg
</div>


## Spatial smoothing using a Gaussian

- Spatial smoothing should signal to noise depending on the size of activation
- Specified using the full-width half max (FWHM) for the Gaussian smoother.  
– Typically, the amount of smoothing is chosen a priori and independently of the data. (ML)
– Usually global smoothing (same amount at each voxel), but can be adaptive (`adimpro` pacakge)

Relationship between the FWHM and the Gaussian $\sigma$:

$$
FWHM = \sigma \sqrt{8 \log(2)}
$$
where $\log$ is the natural log.  




## Spatial smoothing using a Gaussian

```{r smooth, eval = FALSE, echo = TRUE}
smooth_norm = spm12_smooth(
  norm$outfiles[[1]], 
  fwhm = 5, 
  prefix = "s5",
  retimg = FALSE)
```

In many applications, this is the data you will use for post-processing and analysis.  Motion correction has usually been applied above, but some motion correct this data as well. 

## First Level Modeling<br>Single-Subject Model

## Estimate Model 
```{r first_model, eval = FALSE}
output_directory = file.path(run_dir, "output")
if (!dir.exists(output_directory)) {
  dir.create(output_directory)
}
output_directory = normalizePath(output_directory)

################################
# Same model just using condition list
################################
condition_list = list(
  list(name = "LeftHand",
       onset = c(20, 100, 180, 260, 340, 420),
       duration = c(20, 20, 20, 20, 20, 20)
  ),
  list(name = "RightHand",
       onset = c(60, 140, 220, 300, 380, 460),
       duration = c(20, 20, 20, 20, 20, 20)
  )
)
if (have_matlab()) {
  first_model = spm12_first_level(
    scans = smooth_norm$outfiles,
    n_time_points = n_time_points,
    units = "secs",
    slice_timed = FALSE,
    tr = tr,
    condition_list = condition_list,
    regressor_mat = rpfile,
    outdir = output_directory,
    clean = FALSE
  )
  
  cons = list.files(
    pattern = "beta.*[.]nii", 
    path = output_directory,
    full.names = TRUE)
  print(cons)
}
```

## Contrast Manager - Creating Contrasts

```{r conman, eval = FALSE}
contrasts = list(
  list(
    name = "LeftHand",
    weights = c(1, rep(0, 7)),
    replicate = "none",
    type = "T" ),
  list(name = "RightHand",
       weights = c(0, 1, rep(0, 6)),
       replicate = "none",
       type = "T"), 
  list(name = "AllEffects",
       weights = rbind(
         c(1, rep(0, 7)),
         c(0, 1, rep(0, 6))
       ),
       replicate = "none",
       type = "F")   
)

  contrast_res = spm12_contrast_manager(
    spm = first_model$spmmat,
    delete_existing = TRUE,
    contrast_list = contrasts,
    clean = FALSE
  )
```

```{r gzipping, eval = FALSE}
if (have_matlab()) {
  dir(output_directory)
  
  cons = list.files(
    pattern = "con.*[.]nii", path = output_directory,
    full.names = TRUE)
  print(cons)
  stats = list.files(
    pattern = "spm(T|F).*[.]nii", 
    path = output_directory,
    full.names = TRUE)
  print(stats)
  # anat_img = readnii(anat_norm2x2x2$outfiles)
  # stat_t = readnii(stats[2])
}
```


## There is no universal fMRI pipeline

- Each step has inherent drawback and limitation (spatial resolution, artifact smoothing, etc.)
- A few different pipelines should be tested.
    - Not necessarily all combinations, but change the "knobs" a bit
- Similar to sensitivity analysis

## References
